{
    "name": "root",
    "gauges": {
        "PongAgent.Policy.Entropy.mean": {
            "value": 0.8503661155700684,
            "min": 0.8503661155700684,
            "max": 0.8778508305549622,
            "count": 12
        },
        "PongAgent.Policy.Entropy.sum": {
            "value": 17415.498046875,
            "min": 11152.216796875,
            "max": 17870.419921875,
            "count": 12
        },
        "PongAgent.Environment.EpisodeLength.mean": {
            "value": 37.46816479400749,
            "min": 35.23321554770318,
            "max": 38.6,
            "count": 12
        },
        "PongAgent.Environment.EpisodeLength.sum": {
            "value": 10004.0,
            "min": 5841.0,
            "max": 10091.0,
            "count": 12
        },
        "PongAgent.Self-play.ELO.mean": {
            "value": 734.6948223281194,
            "min": 729.9714997920086,
            "max": 736.3010388929359,
            "count": 12
        },
        "PongAgent.Self-play.ELO.sum": {
            "value": 196163.51756160788,
            "min": 119715.32596588941,
            "max": 207889.11652363144,
            "count": 12
        },
        "PongAgent.Step.mean": {
            "value": 3559981.0,
            "min": 3339971.0,
            "max": 3559981.0,
            "count": 12
        },
        "PongAgent.Step.sum": {
            "value": 3559981.0,
            "min": 3339971.0,
            "max": 3559981.0,
            "count": 12
        },
        "PongAgent.Policy.ExtrinsicValueEstimate.mean": {
            "value": 7.978973865509033,
            "min": 7.50018835067749,
            "max": 8.118301391601562,
            "count": 12
        },
        "PongAgent.Policy.ExtrinsicValueEstimate.sum": {
            "value": 3518.7275390625,
            "min": 2137.825927734375,
            "max": 3604.52587890625,
            "count": 12
        },
        "PongAgent.Environment.CumulativeReward.mean": {
            "value": 14.625468164794007,
            "min": 14.342105263157896,
            "max": 15.0,
            "count": 12
        },
        "PongAgent.Environment.CumulativeReward.sum": {
            "value": 3905.0,
            "min": 2445.0,
            "max": 4220.0,
            "count": 12
        },
        "PongAgent.Policy.ExtrinsicReward.mean": {
            "value": 14.625468164794007,
            "min": 14.342105263157896,
            "max": 15.0,
            "count": 12
        },
        "PongAgent.Policy.ExtrinsicReward.sum": {
            "value": 3905.0,
            "min": 2445.0,
            "max": 4220.0,
            "count": 12
        },
        "PongAgent.Losses.PolicyLoss.mean": {
            "value": 0.09435997545547672,
            "min": 0.08627176170698873,
            "max": 0.09825671088917434,
            "count": 12
        },
        "PongAgent.Losses.PolicyLoss.sum": {
            "value": 0.09435997545547672,
            "min": 0.08627176170698873,
            "max": 0.19651342177834868,
            "count": 12
        },
        "PongAgent.Losses.ValueLoss.mean": {
            "value": 0.6966374042536576,
            "min": 0.13552353827657904,
            "max": 0.9159131618517322,
            "count": 12
        },
        "PongAgent.Losses.ValueLoss.sum": {
            "value": 0.6966374042536576,
            "min": 0.13552353827657904,
            "max": 1.8318263237034644,
            "count": 12
        },
        "PongAgent.Policy.LearningRate.mean": {
            "value": 8.708113097298002e-05,
            "min": 8.708113097298002e-05,
            "max": 9.961182679607996e-05,
            "count": 12
        },
        "PongAgent.Policy.LearningRate.sum": {
            "value": 8.708113097298002e-05,
            "min": 8.708113097298002e-05,
            "max": 0.00019554943481689998,
            "count": 12
        },
        "PongAgent.Policy.Epsilon.mean": {
            "value": 0.12902702000000002,
            "min": 0.12902702000000002,
            "max": 0.13320392,
            "count": 12
        },
        "PongAgent.Policy.Epsilon.sum": {
            "value": 0.12902702000000002,
            "min": 0.12902702000000002,
            "max": 0.2651831,
            "count": 12
        },
        "PongAgent.Policy.Beta.mean": {
            "value": 0.000152232398,
            "min": 0.000152232398,
            "max": 0.00017269920799999994,
            "count": 12
        },
        "PongAgent.Policy.Beta.sum": {
            "value": 0.000152232398,
            "min": 0.000152232398,
            "max": 0.00033939718999999996,
            "count": 12
        },
        "PongAgent.IsTraining.mean": {
            "value": 1.0,
            "min": 1.0,
            "max": 1.0,
            "count": 12
        },
        "PongAgent.IsTraining.sum": {
            "value": 1.0,
            "min": 1.0,
            "max": 1.0,
            "count": 12
        }
    },
    "metadata": {
        "timer_format_version": "0.1.0",
        "start_time_seconds": "1709276909",
        "python_version": "3.9.13 (tags/v3.9.13:6de2ca5, May 17 2022, 16:36:42) [MSC v.1929 64 bit (AMD64)]",
        "command_line_arguments": "C:\\Users\\g.renaud\\Documents\\GitHub\\Crossy-Road-AI\\MLvenv\\Scripts\\mlagents-learn pong-config-selfplay.yaml --run-id=pong-selfV3 --resume",
        "mlagents_version": "0.30.0",
        "mlagents_envs_version": "0.30.0",
        "communication_protocol_version": "1.5.0",
        "pytorch_version": "2.2.1+cpu",
        "numpy_version": "1.21.2",
        "end_time_seconds": "1709277335"
    },
    "total": 425.9675096,
    "count": 1,
    "self": 0.010191100000042752,
    "children": {
        "run_training.setup": {
            "total": 0.2971671000000011,
            "count": 1,
            "self": 0.2971671000000011
        },
        "TrainerController.start_learning": {
            "total": 425.66015139999996,
            "count": 1,
            "self": 0.4377194000006739,
            "children": {
                "TrainerController._reset_env": {
                    "total": 25.242239199999993,
                    "count": 2,
                    "self": 25.242239199999993
                },
                "TrainerController.advance": {
                    "total": 399.8808253999993,
                    "count": 10182,
                    "self": 0.4090328999989765,
                    "children": {
                        "env_step": {
                            "total": 144.89034010000043,
                            "count": 10182,
                            "self": 121.59281340000035,
                            "children": {
                                "SubprocessEnvManager._take_step": {
                                    "total": 23.061599600000207,
                                    "count": 10182,
                                    "self": 1.1116973999987394,
                                    "children": {
                                        "TorchPolicy.evaluate": {
                                            "total": 21.949902200001468,
                                            "count": 7681,
                                            "self": 21.949902200001468
                                        }
                                    }
                                },
                                "workers": {
                                    "total": 0.23592709999986283,
                                    "count": 10182,
                                    "self": 0.0,
                                    "children": {
                                        "worker_root": {
                                            "total": 395.83214319999814,
                                            "count": 10182,
                                            "is_parallel": true,
                                            "self": 305.81771749999956,
                                            "children": {
                                                "steps_from_proto": {
                                                    "total": 0.0024100999999987494,
                                                    "count": 2,
                                                    "is_parallel": true,
                                                    "self": 0.0010851000000009492,
                                                    "children": {
                                                        "_process_rank_one_or_two_observation": {
                                                            "total": 0.0013249999999978002,
                                                            "count": 4,
                                                            "is_parallel": true,
                                                            "self": 0.0013249999999978002
                                                        }
                                                    }
                                                },
                                                "UnityEnvironment.step": {
                                                    "total": 90.01201559999859,
                                                    "count": 10182,
                                                    "is_parallel": true,
                                                    "self": 3.482223099993803,
                                                    "children": {
                                                        "UnityEnvironment._generate_step_input": {
                                                            "total": 7.548281700001567,
                                                            "count": 10182,
                                                            "is_parallel": true,
                                                            "self": 7.548281700001567
                                                        },
                                                        "communicator.exchange": {
                                                            "total": 70.51773700000228,
                                                            "count": 10182,
                                                            "is_parallel": true,
                                                            "self": 70.51773700000228
                                                        },
                                                        "steps_from_proto": {
                                                            "total": 8.463773800000933,
                                                            "count": 10182,
                                                            "is_parallel": true,
                                                            "self": 3.862905299999344,
                                                            "children": {
                                                                "_process_rank_one_or_two_observation": {
                                                                    "total": 4.600868500001589,
                                                                    "count": 20364,
                                                                    "is_parallel": true,
                                                                    "self": 4.600868500001589
                                                                }
                                                            }
                                                        }
                                                    }
                                                }
                                            }
                                        }
                                    }
                                }
                            }
                        },
                        "trainer_advance": {
                            "total": 254.58145239999988,
                            "count": 10182,
                            "self": 1.3971729000028859,
                            "children": {
                                "process_trajectory": {
                                    "total": 33.63560909999694,
                                    "count": 10182,
                                    "self": 33.402326499996946,
                                    "children": {
                                        "RLTrainer._checkpoint": {
                                            "total": 0.23328259999999545,
                                            "count": 1,
                                            "self": 0.23328259999999545
                                        }
                                    }
                                },
                                "_update_policy": {
                                    "total": 219.54867040000005,
                                    "count": 20,
                                    "self": 72.665004100001,
                                    "children": {
                                        "TorchPPOOptimizer.update": {
                                            "total": 146.88366629999905,
                                            "count": 11285,
                                            "self": 146.88366629999905
                                        }
                                    }
                                }
                            }
                        }
                    }
                },
                "trainer_threads": {
                    "total": 1.6000000186977559e-06,
                    "count": 1,
                    "self": 1.6000000186977559e-06
                },
                "TrainerController._save_models": {
                    "total": 0.09936579999998685,
                    "count": 1,
                    "self": 0.009442799999987983,
                    "children": {
                        "RLTrainer._checkpoint": {
                            "total": 0.08992299999999886,
                            "count": 1,
                            "self": 0.08992299999999886
                        }
                    }
                }
            }
        }
    }
}